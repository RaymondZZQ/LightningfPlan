# DocUNet:基于堆栈U-Net的文档图像扭曲矫正

**摘要：** <br>（1）由于移动摄像头无处不在，拍摄文档图像来对物理文档进行数字化记录是一种普遍的方式。 <br>（2） 为了使得文本检测更加容易，我们常常希望将一张弯曲的或者折叠的文档图像数字化地展平。<br>（3）本文中，我们首次提出了基于学习的方法来实现这个目标(将扭曲的图像转换为对应的平整的图像)。我们提出了带有“中间监督”的堆栈式UNet直接预测扭曲图像到矫正图像的正向映射。<br>（4）由于大规模具有真实形变的样本很难获得，我们通过对未扭曲的图像进行仿射的方式制作了一个约10万张合成图像的数据集。		  <br>（5）本文的模型在这个训练集上训练并采用多种数据增强的方式来增强网络的泛化性能。<br>（6）制作了一个包含了各种真实世界条件的benchmark（130张各种场景的图像）。<br>（7）在制作的benchmark上进行定量和定性的评估实验，并和之前的非基于学习的方法进行对比。

**1、介绍**<br>   	  文档数字化作为一种重要的保存现有印刷文档的方法，使得用户在任何地点任何时间都可获取这些文档。传统的，文档是使用平板扫描仪来进行数字化的，然而平板扫描仪是不可移动且昂贵的设备。近年来，随着移动摄像头越来越流行，拍摄实物文档图像已经成为最简单扫描文档的方式。一旦拍摄，图像可以进一步地被文本检测与识别的处理，以用于内容分析和信息提取。<br>  	   实际中最常见的问题是当拍摄文档图像时，文档可能不在一个理想的扫描条件下：可能弯曲、折叠、褶皱或者背景特别复杂。想想一下从口袋里拿出皱巴巴的收据。这些原因都可能对自动文档图像分析流程的下游产生严重的问题。如图1所示。因此，对采集到的这种图像进行展平非常值得研究。<br>		以前已经有多种方法用于文档图像展平。有一些是经过精心的设计的校准过的硬件如：立体摄像机或者结构光来测量文档的3D形变。这些方法取得了高质量的结果，但是额外的硬件限制了他们的应用。其他的一些方法[28,36]通过利用多视图来重建变形文档的3D形状从而摆脱了硬件的限制。 其他方法目标是通过分析单张图像，使用多种手工低级特征如光照、阴影和文本行等来重建矫正文档。<br>		本文提出了一种新颖的基于学习的方法来重建自然世界中任意弯曲和折叠的文档图像。不像之前的方法，我们的方法是到首个端到端的基于学习直接预测文档图像变形的方法。之前的方法只是用学习的方式来提取特征，最终的图像重建仍然基于传统的优化流程。我们的方法基于CNNs来完成端到端的文档图像重建。与基于优化的方法相比，前馈神经网络在测试阶段非常的高效。此外，这个数据驱动的方法有很好的泛化性能，只有数据集中有相应的数据，就可以矫正各种类型的文档图像，如文本、图和手写等。<br>		我们将这个任务看作是寻找一个适当的2D图像扭曲，可以矫正形变的图像。我们的网络预测了一个映射场，可以将形变的源图像上的像素点映射到结果图像D中：D(x,y)=S(u,v)<br>		通过这个公式表示这个问题，我们发现这个任务和语义分割有一些共同之处。对于后者，网络对每个像素指定一个标签(类别标签，语义分割问题实际上是一个像素级的分类问题)。相似的，我们的网络对每个像素指定了一个2维向量作为标签。这启发我们使用语义分割中获得广泛成功的U-Net[23]作为我们的网络结构。为了适合我们的回归问题，我们设计了一个新的损失函数来引导网络回归D中每个像素的坐标(x,y)。<br>		获得大量有真实标签的数据是深度监督学习面临的第一个挑战。为了训练我们的网络，我们需要获得大量的以不同角度形变的文档图像和对应的可以用来指导矫正的形变信息。这样的数据集当前不存在。获得物理世界的真实形变信息是非常有挑战的。我们通过随机扭曲平整的文档图像合成了10万张训练图像，因此，扭曲的图像是输入且我们用于扭曲图像的网格是“逆变形”，即我们恢复的目标。<br>		当前没有可以获得的广泛使用的benchmark来评估文档矫正。先前的方法要么是在一个小数据集上评估，就是在只包含一两种形变类型图像(比如平滑弯曲)的数据集上进行评估。我们通过制作了包含多种变形类型的文档图像大约130张填补了这个真空。我们主要的贡献有以下三点:<br>		(1)第一个端到端的基于学习的文档图像矫正算法；<br>		(2)提出了一种合成弯曲或者折叠的文档图像的方法，并通过这种方法制作了10万张训练图像；<br>		(3)制作了一个具有ground truth的不同评估基准的验证数据集，在这个数据集上测试算法的效果。

**2、相关工作**<br>		已经有很多文献研究了文档矫正，我们大致将以前的算法分为两类：<br>		**3D形状重建**    重建文档的3D形状<br>			(1)Brown和Seales[1]使用可见光投影-摄像系统(visible light projector-camera system)<br>			(2)Zhang[38]利用更加先进的距离/深度传感器，且考虑了纸张的物理性质对形状恢复的影响<br>			(3)更近的，Meng[21]搭建了一个平台，使用两束结构激光来获取文档的弯曲。<br>			除了使用额外的硬件设备，其他的一些工作依赖于多视图来重建 3D形状。<br>			(4)Ulges[29]通过图像块匹配的方式计算两张图像的视差图。<br>			(5)Yamashita[35]通过NURBS(non-uniform rational b-splines)来参数化文档图像的3D形状。<br>			(6)Tsoi和Brown[28] 不需要校正过的立体视觉系统，他们使用多视图边界信息并将这些图像组合在一起生成矫正图像。<br>			(7)相似的，Koo[13]使用两个来自不同视图的未校准的图像通过SIFT匹配来估量3D形状。<br>			(8)Ostlund等，提出了一个网格参数化的方法，该方法可以在给定对应参考图像下重建表面形变图像的3D形状。<br>			(9)最近，You[36]通过对多幅图像上的折痕进行建模来重建3D形状。<br>		**低级特征的形状**   低级特征包括：光照/阴影、文本线。<br>			(1)Wada[32]使用阴影的形状(shape from shading,SfS)来建立这个问题，在一个有方向性的光源下，扭曲的文档显示出不同的阴影。<br>  		  (2)Courteille[5] 更进一步地扩展了这个方法，使用摄像头而不是扫描器且通过阴影预测透视形状。<br>			(3)Zhang[37]提出了一个更加鲁棒的SfS系统，该系统可以应对遮挡和背景噪声。<br>			一些其他的方法基于分析文档的内容：如文本线。一个普遍的策略是追踪文本线[8,30,18,21,11,16]，这种策略基于平整图像的文本线是水平直线的假设。相关方法如下：<br>			(4)Gao[2]将弯曲文档建模为圆柱面；<br>			(5)Liang[14]使用了可扩展的表面来建模；<br>			(6)Tian和Narasimhan[27]优化了文本行作为水平线索、字符笔画作为垂直线索来产生3D网格。这些方法都可以看作是来自广义的纹理的形状的特例[34,19,9]。<br>			(7)近来，Das[6]利用CNN来检测纸张的褶皱用于矫正。<br>			然而，CNN仅仅用于他们优化流程的一个步骤，而不是端到端的方式。<br>		我们的方法可以被分到第二类中。但是，和之前的所有方法不同，它是一种纯数据驱动的方法。网络通过端到端的方式训练，预测扭曲的正向映射，因此没有使用低级的手工挑选的特征。 在测试阶段没有优化过程。我们的网络有两个好处：一是只要提供大量的训练数据就可以处理各种类型和条件的文档；二是可以作为一种有效的方法部署到实际应用中。

 